{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtNeBCkyDFWAkTs9PZqAwC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hammaad2002/OnnxConversion/blob/main/Onnxruntime_if_else_statement_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "2wmnW_EhHGm8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 10)\n",
        "        self.fc2 = nn.Linear(10, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.sum() > 0:\n",
        "            return self.fc1(x)\n",
        "        else:\n",
        "            return self.fc2(x)\n",
        "\n",
        "# Create a model instance\n",
        "model = MyModel()\n",
        "\n",
        "# Script the model to cover the whole graph of the model properly\n",
        "scripted_model = torch.jit.script(model)\n",
        "\n",
        "# Dummy input\n",
        "x = torch.randn(1, 10)\n",
        "\n",
        "# Export the scripted model to ONNX\n",
        "torch.onnx.export(scripted_model, x, \"model.onnx\", opset_version=11)"
      ],
      "metadata": {
        "id": "fKY_jVVvGp48"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking first condition"
      ],
      "metadata": {
        "id": "uQNPpRbzMR6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Create onnxruntime session and load the model into it\n",
        "runtime_session = ort.InferenceSession('model.onnx')\n",
        "\n",
        "# Generate a random input tensor\n",
        "input_data = np.random.rand(1, 10).astype(np.float32)\n",
        "\n",
        "# Run the model\n",
        "output = runtime_session.run(output_names=None, input_feed={\"x.1\": input_data})\n",
        "\n",
        "# Print the output\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZj2cpL0IOSK",
        "outputId": "1f58ad34-b7e4-4af9-ea8f-6235b0c5575d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[-0.11374693,  0.11781086,  0.2204764 ,  0.0980921 , -0.12393575,\n",
            "         0.58832127,  0.08381553, -0.06057395, -0.13055053,  0.21798216]],\n",
            "      dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eikzD4BTJ91u",
        "outputId": "500d6fd9-1738-436f-cf8b-b42ac57aeac2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking second condition"
      ],
      "metadata": {
        "id": "YSLb-0G0MUbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Create onnxruntime session and load the model into it\n",
        "runtime_session = ort.InferenceSession('model.onnx')\n",
        "\n",
        "# Generate a random input tensor\n",
        "input_data = np.random.rand(1, 10).astype(np.float32) * -1\n",
        "\n",
        "# Run the model\n",
        "output = runtime_session.run(output_names=None, input_feed={\"x.1\": input_data})\n",
        "\n",
        "# Print the output\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8jjGErMKWB1",
        "outputId": "599e9f1e-d474-4ba6-d7df-e6a50d387107"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 0.33516896, -0.3808381 ,  0.19739884, -0.26054007,  0.3200385 ,\n",
            "        -0.4683231 ,  0.38515747, -0.039433  , -0.76650953,  0.0456315 ,\n",
            "         0.21966675, -0.55031645, -0.00447094,  0.31128544, -0.29129508,\n",
            "        -0.39593104, -0.30141792, -0.3382364 , -0.40622908,  0.0514953 ]],\n",
            "      dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uf2Cv9AKX66",
        "outputId": "0a16ec49-d27c-49c3-c85f-7528d9ebdfa4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}